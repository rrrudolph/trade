{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Swing Finder",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1p2gM_AaQgZ6FboPnU85FxtM2s_2Fkh4J",
      "authorship_tag": "ABX9TyOuMZ52ahkxRzGnH8rsNmkJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rudyselman/trade/blob/master/Swing_Finder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezxmQn_nGqXv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fig.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYpSE51NRdEP",
        "colab_type": "code",
        "outputId": "a4d750e8-ef5c-4c74-d369-96a3f7209f5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 774
        }
      },
      "source": [
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "pd.set_option('display.max_rows', 100)\n",
        "\n",
        "df = pd.read_csv('drive/My Drive/Colab Notebooks/EURUSD15test.csv')\n",
        "\n",
        "# daily = pd.read_csv('drive/My Drive/Colab Notebooks/EURUSD1440.csv')\n",
        "# daily = daily.set_axis(['Date', 'Time','O','H','L','C','V'], axis=1, inplace=False)\n",
        "\n",
        "\n",
        "\n",
        "# # this stuff was to format the original file but is no longer needed\n",
        "\n",
        "# df = df.set_axis(['Date', 'Time','O','H','L','C','V'], axis=1, inplace=False)\n",
        "# df['DT'] = df['Date'] + ' '+df['Time']\n",
        "df['DT'] = pd.to_datetime(df['DT'])\n",
        "# df.drop(columns=['Date','Time'],inplace=True)\n",
        "# df = df.reindex(columns=['DT','O','H','L','C','V','D_Range','ADR','Frac_H','Frac_L'])\n",
        "# df['Datetime'] -= pd.Timedelta(hours=7) # minus 7 hours to match CST\n",
        "\n",
        "\n",
        "\n",
        "# if you want to re-iterate over the highs and lows un-comment these lines:\n",
        "\n",
        "# df['Locked_H'] = 0\n",
        "# df['Locked_L'] = 0\n",
        "# df['Swing'] = 0\n",
        "\n",
        "df = df[64000:]\n",
        "\n",
        "df.reset_index(drop=True,inplace=True)  # reset the index (numbers are missing)\n",
        "\n",
        "df"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DT</th>\n",
              "      <th>O</th>\n",
              "      <th>H</th>\n",
              "      <th>L</th>\n",
              "      <th>C</th>\n",
              "      <th>V</th>\n",
              "      <th>D_Range</th>\n",
              "      <th>ADR</th>\n",
              "      <th>Frac_H</th>\n",
              "      <th>Frac_L</th>\n",
              "      <th>Locked_H</th>\n",
              "      <th>Locked_L</th>\n",
              "      <th>Swing</th>\n",
              "      <th>Swing%</th>\n",
              "      <th>Sw_Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-02-25 14:15:00</td>\n",
              "      <td>1.08358</td>\n",
              "      <td>1.08375</td>\n",
              "      <td>1.08341</td>\n",
              "      <td>1.08349</td>\n",
              "      <td>998</td>\n",
              "      <td>0.00601</td>\n",
              "      <td>0.00492</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-02-25 14:30:00</td>\n",
              "      <td>1.08350</td>\n",
              "      <td>1.08381</td>\n",
              "      <td>1.08342</td>\n",
              "      <td>1.08378</td>\n",
              "      <td>775</td>\n",
              "      <td>0.00601</td>\n",
              "      <td>0.00492</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-02-25 14:45:00</td>\n",
              "      <td>1.08377</td>\n",
              "      <td>1.08381</td>\n",
              "      <td>1.08300</td>\n",
              "      <td>1.08361</td>\n",
              "      <td>902</td>\n",
              "      <td>0.00601</td>\n",
              "      <td>0.00493</td>\n",
              "      <td>0.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-02-25 15:00:00</td>\n",
              "      <td>1.08362</td>\n",
              "      <td>1.08406</td>\n",
              "      <td>1.08356</td>\n",
              "      <td>1.08399</td>\n",
              "      <td>876</td>\n",
              "      <td>0.00601</td>\n",
              "      <td>0.00493</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-02-25 15:15:00</td>\n",
              "      <td>1.08399</td>\n",
              "      <td>1.08472</td>\n",
              "      <td>1.08392</td>\n",
              "      <td>1.08467</td>\n",
              "      <td>955</td>\n",
              "      <td>0.00601</td>\n",
              "      <td>0.00493</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1278</th>\n",
              "      <td>2020-03-13 21:45:00</td>\n",
              "      <td>1.10696</td>\n",
              "      <td>1.11147</td>\n",
              "      <td>1.10637</td>\n",
              "      <td>1.11132</td>\n",
              "      <td>2185</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.01520</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1279</th>\n",
              "      <td>2020-03-13 22:00:00</td>\n",
              "      <td>1.11132</td>\n",
              "      <td>1.11168</td>\n",
              "      <td>1.10807</td>\n",
              "      <td>1.10807</td>\n",
              "      <td>1847</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.01521</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.00372</td>\n",
              "      <td>-0.24</td>\n",
              "      <td>3.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1280</th>\n",
              "      <td>2020-03-13 22:15:00</td>\n",
              "      <td>1.10806</td>\n",
              "      <td>1.10975</td>\n",
              "      <td>1.10796</td>\n",
              "      <td>1.10956</td>\n",
              "      <td>1120</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.01522</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1281</th>\n",
              "      <td>2020-03-13 22:30:00</td>\n",
              "      <td>1.10957</td>\n",
              "      <td>1.11157</td>\n",
              "      <td>1.10946</td>\n",
              "      <td>1.11078</td>\n",
              "      <td>1220</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.01522</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1282</th>\n",
              "      <td>2020-03-13 22:45:00</td>\n",
              "      <td>1.11077</td>\n",
              "      <td>1.11158</td>\n",
              "      <td>1.10967</td>\n",
              "      <td>1.10986</td>\n",
              "      <td>967</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.01523</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1283 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      DT        O        H  ...    Swing  Swing%  Sw_Rating\n",
              "0    2020-02-25 14:15:00  1.08358  1.08375  ...      NaN     NaN        NaN\n",
              "1    2020-02-25 14:30:00  1.08350  1.08381  ...      NaN     NaN        NaN\n",
              "2    2020-02-25 14:45:00  1.08377  1.08381  ...      NaN     NaN        NaN\n",
              "3    2020-02-25 15:00:00  1.08362  1.08406  ...      NaN     NaN        NaN\n",
              "4    2020-02-25 15:15:00  1.08399  1.08472  ...      NaN     NaN        NaN\n",
              "...                  ...      ...      ...  ...      ...     ...        ...\n",
              "1278 2020-03-13 21:45:00  1.10696  1.11147  ...      NaN     NaN        NaN\n",
              "1279 2020-03-13 22:00:00  1.11132  1.11168  ... -0.00372   -0.24        3.3\n",
              "1280 2020-03-13 22:15:00  1.10806  1.10975  ...      NaN     NaN        NaN\n",
              "1281 2020-03-13 22:30:00  1.10957  1.11157  ...      NaN     NaN        NaN\n",
              "1282 2020-03-13 22:45:00  1.11077  1.11158  ...      NaN     NaN        NaN\n",
              "\n",
              "[1283 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upRmlPNugmlf",
        "colab_type": "text"
      },
      "source": [
        "# Get Daily Range \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFoBcVs5QtSR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "for i in df['DT'].dt.date.unique():\n",
        "  group = df.groupby(df['DT'].dt.date).get_group(i)\n",
        "  dayrange = max(group['H']) - min(group['L'])\n",
        "  df.loc[group.index,'D_Range'] = dayrange\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pQKg_dHizuh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlywxxX4aziv",
        "colab_type": "text"
      },
      "source": [
        "alright groupby is my forever friend from now on. \n",
        "\n",
        "#Get ADR\n",
        "\n",
        "There are 96 15m candles per day and I want a 10 day average.  This will give me an index error so it needs a try block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrxA3P4RbMLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(0, len(df)):\n",
        "    try:\n",
        "      df.loc[i,'ADR'] = round(df.loc[i-960:i,'D_Range'].mean(),5)\n",
        "    except:\n",
        "      pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xib9CrRojpQn",
        "colab_type": "text"
      },
      "source": [
        "# Identify Fractals\n",
        "\n",
        "For each bar, walk forwards and backwards to see how far you get while the high remains highest high. Do this individually for both the highs and the lows. While walking forward see how far price moved away from that fractal. The smaller of the 2 counts will be used as the fractal rating.\n",
        "\n",
        "There are 4 try blocks total for the highs, lows, forwards, and backwards. Exceptions are hit when the loop reaches either end of the df. I need these to know whether a row can be locked from further iterations.\n",
        "\n",
        "While a market is unfolding the fractals will need to be recalculated for each bar until the forward walk value has been determined with no errors. Once that happens the value will be locked in place and even though prior fractals may need to be reiterated over, the locked ones will not. This pic show's a locked fractal while a previous fractal needs to still be re-iterated into the future. http://prntscr.com/rhc9zt\n",
        "\n",
        "Unfortunately to account for edge cases I need to create a column specific to highs and lows. \n",
        "\n",
        "There is also a time limit for a fractal to be locked.  Once it is the highest high/lowest low for 120 bars it will be considered a major swing and there's no need to know the exact bar count beyond that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIsh1jsCsCoG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%timeit\n",
        "highs = df.loc[:,'H'].values\n",
        "lows = df.loc[:,'L'].values \n",
        "\n",
        "for i in range(0, len(df)): \n",
        "  low = lows[i]\n",
        "  high = highs[i]\n",
        " \n",
        "  # the order below is highs forwards, highs backwards\n",
        "\n",
        "  if not df.loc[i,'Locked_H']:\n",
        "    try:   # iter forwards \n",
        "      count_prior = 0   # initialize counters and such\n",
        "      count_next = 0\n",
        "      next_ = i + 1\n",
        "      prior_ = i - 1\n",
        "\n",
        "      while high > highs[next_] and count_next < 120: # iter limit\n",
        "        next_ +=1\n",
        "        count_next +=1\n",
        "      df.loc[i,'Locked_H'] = 1 # if it hasn't error'd lock the row \n",
        "    except:\n",
        "      pass\n",
        "\n",
        "    try: # iter backwards\n",
        "      while high >= highs[prior_] and count_prior < 120: \n",
        "        prior_ -=1\n",
        "        count_prior +=1\n",
        "    except:\n",
        "      pass \n",
        "    df.loc[i,'Frac_H'] = min([count_prior, count_next])\n",
        "    try: # this will return the swing size if frac > 1\n",
        "      if df.loc[i,'Frac_H'] > 1:  # the 'min is an empty argument' requires try block\n",
        "        df.loc[i,'Swing'] = min(lows[i+1:i+count_next]) - high\n",
        "    except:\n",
        "      df.loc[i,'Swing'] = 0\n",
        "\n",
        "  # now the same thing but for the lows\n",
        "  if not df.loc[i,'Locked_L']:\n",
        "    try: # iter forwards \n",
        "      count_prior = 0\n",
        "      count_next = 0\n",
        "      next_ = i + 1\n",
        "      prior_ = i - 1\n",
        "\n",
        "      while low < lows[next_] and count_next < 120: \n",
        "        next_ +=1\n",
        "        count_next +=1\n",
        "      df.loc[i,'Locked_L'] = 1 # if it hasn't error'd set the lock value \n",
        "    except:\n",
        "      pass\n",
        "\n",
        "    try: # iter backwards\n",
        "      while low <= lows[prior_] and count_prior < 120: \n",
        "        prior_ -=1\n",
        "        count_prior +=1\n",
        "      \n",
        "    except:\n",
        "      pass\n",
        "    df.loc[i,'Frac_L'] = min([count_prior, count_next])\n",
        "\n",
        "    # find swing distance\n",
        "    # only overwrite if the new value is greater than the last\n",
        "    try:  \n",
        "      if (max(highs[i:i+count_next]) - low > abs(df.loc[i,'Swing'])\n",
        "          and df.loc[i,'Frac_L'] > 1):\n",
        "        df.loc[i,'Swing'] = max(highs[i+1:i+count_next]) - low\n",
        "    except:\n",
        "        pass\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4G7wBiyF9qxW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "60cfa5d4-894d-4851-b823-5bb71a4cb656"
      },
      "source": [
        "# pandas attempt 2\n",
        "\n",
        "# i have to supply row numbers incrementally so it seems I cant\n",
        "# avoid at least the inital loop\n",
        "\n",
        "# it looks like having the same length of arrays to vectorize\n",
        "# over is unavoidable so I wonder if I could just create a tempory\n",
        "# array filled with copies of df.loc[i]\n",
        "df['i'] = df.index[2]\n",
        "df['i']\n",
        "\n",
        "\n",
        "df['H'][df.index < df['i'].all()]\n",
        "\n",
        "# last_highest = max(df['H']([df.index < df.iloc[i].index).all() &\n",
        "#                       (df['H'] < df.loc[i,'H']).all()])\n",
        "\n",
        "# for i in range(0, len(df)): \n",
        "#   low = lows[i]\n",
        "#   high = highs[i]\n",
        "# df['H'][df.loc[:i-1].index] < df.iloc[i].index"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1.08375\n",
              "Name: H, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2-Dic0Iqu9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head(30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "go33ubiZyR5Z",
        "colab_type": "text"
      },
      "source": [
        "# Swings\n",
        "\n",
        "I need to know the swing size in relation to the average daily range in order for it to mean anything.\n",
        "\n",
        "Also, a fractal size needs to correlate to its swing size.  A large fractal with a tiny swing is mostly irrelevent as that would signify a sideways market. Likewise a large swing on a tiny fractal would signify it was just a slight pullback within a larger swing. Here is an example: http://prntscr.com/rhc2qh\n",
        "\n",
        "In that situation it would be best to only look at the fractals from further up. \n",
        "\n",
        "So I also need a swing rating which will be a combination of fractal size and swing%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyTqBV1fO4NV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get the swing in relation to ADR\n",
        "df['Swing%'] = round(df['Swing']/df['ADR'], 2)\n",
        "\n",
        "# get the swing rating in relation to fractal size\n",
        "temp = df[abs(df['Swing']) > 0]\n",
        "df['Sw_Rating'] = (abs(temp['Swing%']*15) + temp['Frac_H'] + temp['Frac_L']) / 2\n",
        "# technically thats not perfect but it will work for most cases\n",
        "# and I can come back to it later"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcRf5dkkztLk",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "```\n",
        "df['Sw_Rating'].describe()\n",
        "\n",
        "count    17555.000000\n",
        "mean         8.498616\n",
        "std         12.295569\n",
        "min          1.075000\n",
        "25%          2.425000\n",
        "50%          4.150000\n",
        "75%          8.700000\n",
        "max         94.975000\n",
        "Name: Sw_Rating, dtype: float64\n",
        "```\n",
        "# Conclusion\n",
        "\n",
        "My original idea was just to map peaks and troughs so I can identify when certain patterns happen.  I can use the swing ratings though for a variety of things like:\n",
        "- creating adaptive support and resistance zones that will remain valid for a time period in relation to the swing ratings that created it\n",
        "- looking for small swings near each other where each one is progressively higher or lower and volume is fading\n",
        "- other cool things I can't think of"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9v0zvJ-TDVQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# overwrite the file\n",
        "\n",
        "# df.to_csv('EURUSD15test.csv', index=False)\n",
        "# !cp EURUSD15test.csv \"drive/My Drive/Colab Notebooks/\"  \n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFHaKWfrIXUF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# xx.sort_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKhPnuhXbvcJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "df = df[50:]\n",
        "\n",
        "fig = go.Figure(data=[go.Candlestick(x=df['DT'],\n",
        "                open=df['O'], high=df['H'],\n",
        "                low=df['L'], close=df['C'])\n",
        "                      ])\n",
        "xx = df['DT'][df['Swing'] < 0].append(df['DT'][df['Swing'] > 0])\n",
        "xx = xx.sort_index()\n",
        "yy = df['H'][df['Swing'] < 0].append(df['L'][df['Swing'] > 0])\n",
        "yy = yy.sort_index()\n",
        "# yy = df['L'][df['Sw_Rating'] > 0]\n",
        "aa = df\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=xx,\n",
        "    y=yy,\n",
        "    mode=\"lines+markers+text\",\n",
        "    name=\"Lines, Markers and Text\",\n",
        "    # text=str(yy.values),\n",
        "    textposition=\"top center\"\n",
        "))\n",
        "fig.show()\n",
        "\n",
        "# len(df['DT'][df['Sw_Rating'] > 0])\n",
        "len(xx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWLpdMaQkZg6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55NGQI4_shUF",
        "colab_type": "text"
      },
      "source": [
        "potential trade triggers:\n",
        "1. low vol pin bar http://prntscr.com/rg3go1\n",
        "2. Scenario B: consecutive bars of same direction with decreasing vol. http://prntscr.com/rg3kf1\n",
        "3. if I identify lots of similar swing prices in a short span of time I can do trades to catch stop hunts http://prntscr.com/rgz9js - or swing size to fractal size is high and daily range is small (which would mean theres lots of volatility going nowhere)\n",
        "\n",
        "Zones creation:\n",
        "\n",
        "2. http://prntscr.com/rg3kf1 ( Scenario A: high volume bars that are follwed by a lower vol bar and an impulse. Entry could be a low vol opposing candle in zone.  All candles from Scenario B could also be used as a zone. Low vol rejections.  Prior swings at the same price area could be a rating factor.\n"
      ]
    }
  ]
}